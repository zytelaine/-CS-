## 机器学习

### 一、机器学习

机器学习算法是能从数据中学习的算法

机器学习能建构刻画数据中所含语义概念或分布结构等信息的模型。

#### 1.经验分类：

**监督学习：**数据集中包含标签。目标：学习输入输出的映射关系

**无监督学习：**数据集无标签，学习映射函数。目标：发现数据的潜在关联，**聚类**

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615131952457.png" alt="image-20250615131952457" style="zoom:33%;" />

**强化学习：**智能体通过动作与环境进行交互，以长期回报最大化为目标，学习在不确定的环境中进行决策的过程。目标是：学习最优决策策略，最大化累计回报。

#### 2.任务不同分类：

分类任务：输出y是一个离散值

回归任务：输出y是一个连续的预测数值

生成任务：输出和训练数据相似的新数据

分类和回归有**相似的模型架构**，**最后一层激活函数和损失函数**不一样；分类用**softmax和交叉熵**；回归用***线性激活***和**均方误差损失函数**

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615132433261.png" alt="image-20250615132433261" style="zoom:33%;" />



<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615132531097.png" alt="image-20250615132531097" style="zoom:50%;" />

#### 3.性能度量

损失函数

**经验风险：**映射函数在训练集上产生的**误差损失**

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615132829593.png" alt="image-20250615132829593" style="zoom: 50%;" />

**期望风险：**在所有数据中产生的误差损失，真实风险真实误差

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615132852725.png" alt="image-20250615132852725" style="zoom:50%;" />

一批数据反复训练，模型变复杂，经验风险降低，但是err取值增大，期望风险增加，产生**过拟合**

**泛化能力：**模型在训练集和测试集上的性能表现一致

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615133054088.png" alt="image-20250615133054088" style="zoom:33%;" />

### 二、监督学习

通过给定带有标签信息数据的训练集，学习一个从输入xi到输出yi的映射

监督学习算法从*假设空间*学习得到的**决策函数**f（最优映射函数）实现数据分类和识别。

基本假设：**独立同分布**

- **假设空间H：**指模型可以表示的**所有可能**的输入-输出**映射函数的集合**



<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615133850402.png" alt="image-20250615133850402" style="zoom: 33%;" />

训练集、验证集、测试集

在训练集上训练模型的**同时会在验证集上对模型进行评估**，以便得到最佳参数，最后在**测试集**上进行测试，将测试结果作为模型性能最终结果。

三个数据应该没有任何交叉

### 三、回归分析

对不同变量之间的关系研究叫做回归分析，描述不同变量间的关系的模型叫回归模型

#### 回归分类：

1.涉及变量的多少：一元回归、多元回归

2.自变量和因变量之间的关系：线性回归、非线性回归

计算误差综合L，用最小二乘法找到误差最小，对ab求导，得到参数ab的值

最小化：
<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250619191459745.png" alt="image-20250619191459745" style="zoom:50%;" />

多元线性回归，m个训练数据（xi,yi）其中xi是d维度的数据，**要找到一组参数a**=[a0,a1....,ad]

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250619191420742.png" alt="image-20250619191420742" style="zoom:33%;" />

sigmoid一般适用于二分类问题，softmax可以处理多分类问题

### 四、决策树

决策树从一组训练数据中学习到函数，一个树表示一个函数：y=f(x);x：一个属性值向量，**y：一个决策**

决策树将分类问题分解成几个基于单独信息的推理问题，用树状结构逐步完成判断

内部节点：对输入的一个特征

边：结点对应的特征值

叶子节点：实例所属的最终分类

建立决策树：选择属性值，根据属性值划分样本，再进行下一个属性值划分，直到每个子集为同一个类别

**决策树的目标：**找到和训练集一致的**较小的树**(树中**所有的路径都很短，树的规模比较小)**

**思想：**递归地将“最好”的属性作为根或子树的根，这样较少的测试就可以实现分类，理想的属性是将实例分为只含有正例或只含反例的集合

`“最好”：分类能力最好`

**信息熵：**描述信息不确定性的程度；正比关系

在决策树中，选择一个属性划分样本前后，**样本的信息熵减少量**被称为**信息增益**，描述了样本集合复杂度（不确定性）的减少程度

集合样本D最终可以划分为k个信息，第k个信息发生的概率pk。

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615142106839.png" alt="image-20250615142106839" style="zoom:33%;" />

![image-20250615142450449](C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615142450449.png)

![image-20250615142500965](C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615142500965.png)

![image-20250615142511805](C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615142511805.png)

![image-20250615142526145](C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615142526145.png)

- 计算每个属性带来的信息增益
- 选择信息增益最大的作为最佳属性，从上到下构建决策树
- 划分后的不同样本集只存在同类样本，停止划分

### 五、无监督学习

没有“输入-输出”关系对的数据；只有输入，没有输出；目标不明确

#### 常见的无监督聚类算法：

1.聚类：将样本自动归类到一个类别之中。根据样本之间的相似性，划分样本至不同类别；不同的相似度计算方法，会得到不一样的聚类结果。欧式距离法

2.降维：将高纬度的数据映射到低维空间。保留重要信息，去除冗余特征，提高计算效率

助于可视化和模型性能的提升

### 六、聚类算法

**同一类别内的对象相似度较高，不同类别之间的相似度较低。**

**基本步骤：**选择*相似度度量方法*、选择*聚类算法*、确定*聚类数目*、*聚类分析结果*

#### 1、k-means算法

将n个d维度的数据划分为**k个聚簇**，让各个**簇内的方差最小化**。k-means找到一个**局部最优解**。没有其他的聚类结果能让簇内的方差更小，**不能保障有全局最优**。并且k-means容**易受到初始值**影响，是一个**迭代算法**；可以用**不一样的初始值迭代几次**，然后**找到局部最优解。**

1.初始化：随机选择几个点作为聚类中心

2.分配：将每个点分进最近的簇中心，**欧式距离**

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615144746964.png" alt="image-20250615144746964" style="zoom: 67%;" />

3.更新：重新计算每个簇中心，簇内的均值。根据聚类结果更新聚类质心，求均值得到新的质心

4.迭代：重复23，直到簇中心不再变化，或者到达预期的迭代次数

**操作简单高效，可以用于大规模数据**

**容易受到异常值影响**

### 七、特征降维

#### 1、线性判别分析（LDA）：基于监督学习的降维方法

对于一组**有标签信息**的**高维**数据样本，LDA利用类别信息，将它**线性投影**到一个低维空间上，在低维空间中同类样本尽可能靠近，不同类远离

1.根据输入的数据x和标签y，计算每个类别的均值向量mi和总均值m

2.计算类内散度矩阵Sw

3.计算类间散度矩阵Sb

4.求解Sw-1Sb的前r个最大特征值和特征向量，获得投影矩阵W

5.用W将数据x投影到低维空间，降维

#### 2、主成分分析（PCA）：无监督学习的特征降维，分析找到数据特征的主要成分，使用主要成分来代替原始数据

“降维后的结果要保持原始数据的原有结构”

**思想：**将d维特征数据映射到l维空间，去除原始数据之间的冗余性，将**原始数据向数据方差最大的方向投影**。有了最大方差投影方向后，继续找第二方向投影，使每一维的方差尽量大。

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615150444039.png" alt="image-20250615150444039" style="zoom:67%;" />

皮尔逊相关系数：将两组变量的关联度规整到一定的取值范围内

1.对每个样本进行去中心化处理

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615150658513.png" alt="image-20250615150658513" style="zoom:50%;" />

2.计算样本原始数据的协方差矩阵

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615150734658.png" alt="image-20250615150734658" style="zoom:50%;" />

3.对协方差矩阵进行特征值分解，对所得特征根进行排序

4.取前l个最大的特征根所对应的特征向量w1,w2.....wl组成映射矩阵

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615151001451.png" alt="image-20250615151001451" style="zoom:67%;" />

**主成分分析可用于人脸特征识别**

### 八、演化算法

#### 1.演化算法EA：启发式随机优化算法。“突变重组”and“自然选择”

有很多实现方法：遗传算法、遗传规划、演化策略

- 遗传算法GA：选择、交叉、变异。

<img src="C:\Users\Zhao Yitong\AppData\Roaming\Typora\typora-user-images\image-20250615151902458.png" alt="image-20250615151902458" style="zoom: 50%;" />

1.初始化

2.计算每个个体适应值,得到best

3.用轮盘赌选择法选择，产生同样规模的种群

4.染色体交叉

5.染色体变异

6.计算各个种群的适应值，更新原有best

7.超过最大进化代数或到误差要求算法结束，否则返回3

